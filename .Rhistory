summary(weather_df)
weather_df %>%
select(relative_humidity, dry_bulb_temp_f, precip, wind_speed, station_pressure) %>%
cor( use = "pairwise.complete.obs", method = "pearson") # The largest correlations with precip are relative_humidity (weakly positive) and station pressure (weakly negative)
set.seed(1234)
weather_split <- initial_split(data = weather_df, prop = 0.8)
train_data <- training(weather_split)
test_data <- testing(weather_split)
train_data_long <- melt(train_data)
ggplot(train_data_long, aes(x = value)) +
geom_histogram(bins = 50, fill = "grey30") +
facet_wrap(~variable, scales = "free") +
labs(x = "Variable", y = "Frequency (bins = 50)")+
ggtitle(label = "Training Set Histogram Plots of JFK Airport Weather Data")
ggplot(train_data_long, aes(x = variable, y = value)) +
geom_boxplot(width = .3, fill = "lightcoral", color = "black", alpha = .3) +
geom_jitter(width = 0.02, color = "grey20", alpha = .05) +
facet_wrap(~variable, scales = "free") +
labs(x = "Variables", y = "Values")+
guides(color = FALSE) +
ggtitle(label = "Training Set Box Plots of JFK Airport Weather Data")
lm_precip_humidity <- lm(precip ~ relative_humidity, data = train_data)
ggplot(lm_precip_humidity, aes(x = relative_humidity, y = precip)) +
geom_point(color = "grey30") +
geom_jitter(width = 0.3, alpha = 0.2) +
stat_smooth(method = "lm", col = "red")
summary(lm_precip_humidity) # R^2 = 0.03742
lm_precip_dry <- lm(precip ~ dry_bulb_temp_f, data = train_data)
ggplot(lm_precip_dry, aes(x = dry_bulb_temp_f, y = precip)) +
geom_point(color = "grey30") +
geom_jitter(width = 0.3, alpha = 0.2) +
stat_smooth(method = "lm", col = "red")
summary(lm_precip_dry)
lm_precip_wind <- lm(precip ~ wind_speed, data = train_data)
ggplot(lm_precip_wind, aes(x = wind_speed, y = precip)) +
geom_point(color = "grey30") +
geom_jitter(width = 0.3, alpha = 0.2) +
stat_smooth(method = "lm", col = "red")
summary(lm_precip_wind)
lm_precip_pressure <- lm(precip ~ station_pressure, data = train_data)
ggplot(lm_precip_pressure, aes(x = station_pressure, y = precip)) +
geom_point(color = "grey30") +
geom_jitter(width = 0.3, alpha = 0.2) +
stat_smooth(method = "lm", col = "red")
summary(lm_precip_pressure) # R^2 = 0.01896
mlr_spec <- linear_reg() %>%
set_engine(engine = "lm") # Set the model type
train_fit_mlr <- mlr_spec %>%
fit(precip ~ relative_humidity + station_pressure, data = train_data) # Fit the model to a multiple linear regression model
train_results_mlr <- train_fit_mlr %>%
predict(new_data = train_data) %>%
mutate(truth = train_data$precip) # Pass the training data through the model to find performance metrics
rmse(train_results_mlr, truth = truth, estimate = .pred) # rmse = 0.04421933
rsq(train_results_mlr, truth = truth, estimate = .pred) # R^2 = 0.04616237 --> Percent variation that can be explained by the model.
poly_spec <- linear_reg() %>%
set_engine(engine ="lm")
train_fit_poly <- poly_spec %>%
fit(precip ~ poly(relative_humidity, 2, raw = TRUE), data = train_data) # Fit the model to a linear regression model with a quadratic term
train_results_poly <- train_fit_poly %>%
predict(new_data = train_data) %>%
mutate(truth = train_data$precip)
rmse(train_results_poly, truth = truth, estimate = .pred) # rmse = 0.043931
rsq(train_results_poly, truth = truth, estimate = .pred) # r^2 = 0.05856079
ggplot(train_data, aes(x = relative_humidity, y = precip)) + # Visualization of linear model with quadratic term
geom_point(color = "gray30") +
geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red")
set.seed(1234)
weather_recipe <- recipe(precip ~ ., data = train_data)
tune_spec <- linear_reg(penalty = tune(), mixture = 0) %>%  # A ridge regression model is tuned
set_engine("glmnet")
ridge_wf <- workflow() %>%
add_recipe(weather_recipe)
weather_cvfolds <- vfold_cv(train_data) # Cross validation is needed for the grid search below
lambda_grid <- grid_regular(levels = 50, penalty(range = c(-3,0.3)))# A grid search is used to tune the lambda hyperparameter
ridge_grid <- tune_grid(
ridge_wf %>%
add_model(tune_spec), resamples = weather_cvfolds, grid = lambda_grid)
show_best(ridge_grid, metric = "rmse") # A lambda of 0.0064 gives the lowest RMSE of 0.0404
show_best(ridge_grid, metric = "rsq") # A lambda of 0.0016 gives the highest R^2 of 0.0683
ridge_grid %>% # visualization of RMSE metric
collect_metrics() %>%
filter(.metric == "rmse") %>%
ggplot(aes(penalty, mean)) +
geom_line(size=1, color="red") +
scale_x_log10() +
ggtitle("Grid Search Results: RMSE")
ridge_grid %>% # visualization of R^2 metric
collect_metrics() %>%
filter(.metric == "rsq") %>%
ggplot(aes(penalty, mean)) +
geom_line(size=1, color="red") +
scale_x_log10() +
ggtitle("Grid Search Results: R-Squared")
test_fit_mlr <- mlr_spec %>%
fit(precip ~ relative_humidity + station_pressure, data = test_data)
test_results_mlr <- test_fit_mlr %>%
predict(new_data = test_data) %>%
mutate(truth = test_data$precip) # Pass the testing data through the model to find performance metrics
rsq(test_results_mlr, truth = truth, estimate = .pred) # R^2 = 0.04616237
test_fit_mlr <- mlr_spec %>%
fit(precip ~ relative_humidity + station_pressure, data = test_data)
test_results_mlr <- test_fit_mlr %>%
predict(new_data = test_data) %>%
mutate(truth = test_data$precip) # Pass the testing data through the model to find performance metrics
rsq(test_results_mlr, truth = truth, estimate = .pred) # R^2 = 0.04616237
test_fit_mlr <- mlr_spec %>%
fit(precip ~ relative_humidity + station_pressure, data = test_data)
test_results_mlr <- test_fit_mlr %>%
predict(new_data = test_data) %>%
mutate(truth = test_data$precip) # Pass the testing data through the model to find performance metrics
rsq(test_results_mlr, truth = truth, estimate = .pred) # R^2 = 0.04616237
test_fit_mlr <- mlr_spec %>%
fit(precip ~ relative_humidity + station_pressure, data = test_data)
test_results_mlr <- test_fit_mlr %>%
predict(new_data = test_data) %>%
mutate(truth = test_data$precip) # Pass the testing data through the model to find performance metrics
rsq(test_results_mlr, truth = truth, estimate = .pred) # R^2 = 0.04616237
mlr_spec <- linear_reg() %>%
set_engine(engine = "lm")
test_fit_mlr <- mlr_spec %>%
fit(precip ~ relative_humidity + station_pressure, data = test_data)
test_results_mlr <- test_fit_mlr %>%
predict(new_data = test_data) %>%
mutate(truth = test_data$precip) # Pass the testing data through the model to find performance metrics
rsq(test_results_mlr, truth = truth, estimate = .pred) # R^2 = 0.0676
set.seed(1234)
weather_split <- initial_split(data = weather_df, prop = 0.8)
train_data <- training(weather_split)
test_data <- testing(weather_split)
poly_spec <- linear_reg() %>%
set_engine(engine ="lm")
test_fit_poly <- poly_spec %>%
fit(precip ~ poly(relative_humidity, 2, raw = TRUE), data = test_data)
test_results_poly <- test_fit_poly %>%
predict(new_data = test_data) %>%
mutate(truth = test_data$precip)
rsq(test_results_poly, truth = truth, estimate = .pred) # r^2 = 0.05856079
ggplot(test_data, aes(x = relative_humidity, y = precip)) +
geom_point(color = "gray30") +
geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red")
set.seed(1234)
weather_recipe <- recipe(precip ~ ., data = test_data)
tune_spec <- linear_reg(penalty = tune(), mixture = 0) %>%  # A ridge regression model is tuned
set_engine("glmnet")
ridge_wf <- workflow() %>%
add_recipe(weather_recipe)
weather_cvfolds <- vfold_cv(test_data)
lambda_grid <- grid_regular(levels = 50, penalty(range = c(-3,0.3)))
ridge_grid <- tune_grid(
ridge_wf %>%
add_model(tune_spec), resamples = weather_cvfolds, grid = lambda_grid)
show_best(ridge_grid, metric = "rsq") # A lambda of 0.0016 gives the highest R^2 of 0.0
ridge_grid %>% # visualization of R^2 metric
collect_metrics() %>%
filter(.metric == "rsq") %>%
ggplot(aes(penalty, mean)) +
geom_line(size=1, color="red") +
scale_x_log10() +
ggtitle("Grid Search Results: R-Squared")
set.seed(1234)
weather_recipe <- recipe(precip ~ ., data = test_data)
tune_spec <- linear_reg(penalty = tune(), mixture = 0) %>%  # A ridge regression model is tuned
set_engine("glmnet")
ridge_wf <- workflow() %>%
add_recipe(weather_recipe)
weather_cvfolds <- vfold_cv(test_data)
lambda_grid <- grid_regular(levels = 50, penalty(range = c(-3,0.3)))
ridge_grid <- tune_grid(
ridge_wf %>%
add_model(tune_spec), resamples = weather_cvfolds, grid = lambda_grid)
show_best(ridge_grid, metric = "rsq") # A lambda of 0.0016 gives the highest R^2 of 0.0
ridge_grid %>% # visualization of R^2 metric
collect_metrics() %>%
filter(.metric == "rsq") %>%
ggplot(aes(penalty, mean)) +
geom_line(size=1, color="red") +
scale_x_log10() +
ggtitle("Grid Search Results: R-Squared")
mlr_spec <- linear_reg() %>%
set_engine(engine = "lm")
test_fit_mlr <- mlr_spec %>%
fit(precip ~ relative_humidity + station_pressure, data = test_data)
test_results_mlr <- test_fit_mlr %>%
predict(new_data = test_data) %>%
mutate(truth = test_data$precip) # Pass the testing data through the model to find performance metrics
rsq(test_results_mlr, truth = truth, estimate = .pred) # R^2 = 0.0676
poly_spec <- linear_reg() %>%
set_engine(engine ="lm")
test_fit_poly <- poly_spec %>%
fit(precip ~ poly(relative_humidity, 2, raw = TRUE), data = test_data)
test_results_poly <- test_fit_poly %>%
predict(new_data = test_data) %>%
mutate(truth = test_data$precip)
rsq(test_results_poly, truth = truth, estimate = .pred) # r^2 = 0.0894
ggplot(test_data, aes(x = relative_humidity, y = precip)) +
geom_point(color = "gray30") +
geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red")
poly_spec <- linear_reg() %>%
set_engine(engine ="lm")
test_fit_poly <- poly_spec %>%
fit(precip ~ poly(relative_humidity, 2, raw = TRUE), data = test_data)
test_results_poly <- test_fit_poly %>%
predict(new_data = test_data) %>%
mutate(truth = test_data$precip)
rsq(test_results_poly, truth = truth, estimate = .pred) # r^2 = 0.0894
ggplot(test_data, aes(x = relative_humidity, y = precip)) +
geom_point(color = "gray30") +
geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red")
set.seed(1234)
weather_recipe <- recipe(precip ~ ., data = test_data)
tune_spec <- linear_reg(penalty = tune(), mixture = 0) %>%  # A ridge regression model is tuned
set_engine("glmnet")
ridge_wf <- workflow() %>%
add_recipe(weather_recipe)
weather_cvfolds <- vfold_cv(test_data)
lambda_grid <- grid_regular(levels = 50, penalty(range = c(-3,0.3)))
ridge_grid <- tune_grid(
ridge_wf %>%
add_model(tune_spec), resamples = weather_cvfolds, grid = lambda_grid)
show_best(ridge_grid, metric = "rsq") # A lambda of 0.0010 gives the highest R^2 of 0.1374621
ridge_grid %>% # visualization of R^2 metric
collect_metrics() %>%
filter(.metric == "rsq") %>%
ggplot(aes(penalty, mean)) +
geom_line(size=1, color="red") +
scale_x_log10() +
ggtitle("Grid Search Results: R-Squared")
model_names <- c("MLR Model", "Quadratic Polynomial Model", "Regularized MLR Model")
train_rsq_error <- c(0.04616237, 0.05856079, 0.06829497)
test_error <- c(0.06760682, 0.0893642, 0.1374621)
comparison_df <- data.frame(model_names, train_error, test_error)
model_names <- c("MLR Model", "Quadratic Polynomial Model", "Regularized MLR Model")
train_rsq_error <- c(0.04616237, 0.05856079, 0.06829497)
test_rsq_error <- c(0.06760682, 0.0893642, 0.1374621)
comparison_df <- data.frame(model_names, train_rsq_error, test_rsq_error)
print(comparison_df)
(comparison_df)
str(comparison_df)
skim_without_names(comparison_df)
glimpse(comparison_df)
print(comparison_df)
train_rsq_error <- c(0.04616237, 0.05856079, 0.06829497)
model_names <- c("MLR Model", "Quadratic Polynomial Model", "Regularized MLR Model")
train_rsq_error <- c(0.04616237, 0.05856079, 0.06829497)
test_rsq_error <- c(0.06760682, 0.0893642, 0.1374621)
comparison_df <- data.frame(model_names, train_rsq_error, test_rsq_error)
print(comparison_df)
best_performing_model <- max(comparison_df$test_rsq_error)
print(best_performing_model)
print(comparison_df)
comparison_df %>%
filter(max(test_rsq_error))
comparison_df %>%
filter(test_rsq_error = max(test_rsq_error))
comparison_df %>%
filter(test_rsq_error == max(test_rsq_error))
best_performing_model_df <- comparison_df %>%
filter(test_rsq_error == max(test_rsq_error))
print(best_performing_model_df)
best_performing_model_df <- comparison_df %>%
filter(test_rsq_error == max(test_rsq_error)) %>%
mutate(best_performing_model = model_names)
print(best_performing_model_df)
best_performing_model_df <- comparison_df %>%
filter(test_rsq_error == max(test_rsq_error)) %>%
mutate(model_names = best_performing_model)
print(best_performing_model_df)
best_performing_model_df <- comparison_df %>%
filter(test_rsq_error == max(test_rsq_error)) %>%
mutate(model_names = "best_performing_model")
print(best_performing_model_df)
best_performing_model_df <- comparison_df %>%
filter(test_rsq_error == max(test_rsq_error)) %>%
mutate(best_performing_model = model_names)
print(best_performing_model_df)
best_performing_model_df <- comparison_df %>%
filter(test_rsq_error == max(test_rsq_error)) %>%
rename(model_names = best_performing_model)
best_performing_model_df <- comparison_df %>%
filter(test_rsq_error == max(test_rsq_error)) %>%
rename(model_names == best_performing_model)
best_performing_model_df <- comparison_df %>%
filter(test_rsq_error == max(test_rsq_error)) %>%
rename(best_performing_model = model_names)
print(best_performing_model_df)
# Install tidymodels if you haven't done so
# install.packages("rlang")
# install.packages("tidymodels")
# install.packages("reshape2")
# Libraries for modeling
library(tidymodels)
library(rlang)
# Libraries for processing & analysis
library(tidyverse)
library(stringr)
library(reshape2)
url <- "https://dax-cdn.cdn.appdomain.cloud/dax-noaa-weather-data-jfk-airport/1.1.4/noaa-weather-sample-data.tar.gz"
download.file(url, destfile = "noaa-weather-sample-data.tar.gz")
untar("noaa-weather-sample-data.tar.gz", tar = "internal")
weather_jfk <- read.csv("noaa-weather-sample-data/jfk_weather_sample.csv")
head(weather_jfk)
glimpse(weather_jfk)
sub_weather <- weather_jfk %>%
select(
HOURLYRelativeHumidity,
HOURLYDRYBULBTEMPF,
HOURLYPrecip,
HOURLYWindSpeed,
HOURLYStationPressure
)
head(sub_weather, 10)
unique(sub_weather$HOURLYPrecip)
replace_T_and_s <- sub_weather %>%
mutate(HOURLYPrecip = str_replace(HOURLYPrecip, "T", "0.0")) %>%
mutate(HOURLYPrecip = str_remove(HOURLYPrecip, "s$"))
unique(replace_T_and_s$HOURLYPrecip)
glimpse(replace_T_and_s)
convert_numeric <- replace_T_and_s %>%
mutate(HOURLYPrecip = as.numeric(HOURLYPrecip))
glimpse(convert_numeric)
map(convert_numeric, ~sum(is.na(.)))
weather_df <- convert_numeric %>%
rename(
relative_humidity = HOURLYRelativeHumidity,
dry_bulb_temp_f = HOURLYDRYBULBTEMPF,
precip = HOURLYPrecip,
wind_speed = HOURLYWindSpeed,
station_pressure = HOURLYStationPressure
) %>%
drop_na( # Removed missing values for computation requirements below
relative_humidity,
dry_bulb_temp_f,
precip,
wind_speed,
station_pressure
)
str(weather_df)
map(weather_df, ~sum(is.na(.)))
weather_df_long <- melt(weather_df, id.vars = "precip")
# transforms data from wide to long, creates the three columns: variable (name of predictors), value (their values), and the precip target variable
ggplot(weather_df_long, aes(x = value, y = precip)) +
geom_point(color = "grey30") +
facet_wrap(~variable, scales = "free") +
labs(x = "Predictor Variable", y = "Precipitation (inches per hour)") +
ggtitle(label = "Scatter Plots of JFK Airport Weather Variables vs Precipitation")
summary(weather_df)
weather_df %>%
select(relative_humidity, dry_bulb_temp_f, precip, wind_speed, station_pressure) %>%
cor( use = "pairwise.complete.obs", method = "pearson") # The largest correlations with precip are relative_humidity (weakly positive) and station pressure (weakly negative)
set.seed(1234)
weather_split <- initial_split(data = weather_df, prop = 0.8)
train_data <- training(weather_split)
test_data <- testing(weather_split)
train_data_long <- melt(train_data)
ggplot(train_data_long, aes(x = value)) +
geom_histogram(bins = 50, fill = "grey30") +
facet_wrap(~variable, scales = "free") +
labs(x = "Variable", y = "Frequency (bins = 50)")+
ggtitle(label = "Training Set Histogram Plots of JFK Airport Weather Data")
ggplot(train_data_long, aes(x = variable, y = value)) +
geom_boxplot(width = .3, fill = "lightcoral", color = "black", alpha = .3) +
geom_jitter(width = 0.02, color = "grey20", alpha = .05) +
facet_wrap(~variable, scales = "free") +
labs(x = "Variables", y = "Values")+
guides(color = FALSE) +
ggtitle(label = "Training Set Box Plots of JFK Airport Weather Data")
lm_precip_humidity <- lm(precip ~ relative_humidity, data = train_data)
ggplot(lm_precip_humidity, aes(x = relative_humidity, y = precip)) +
geom_point(color = "grey30") +
geom_jitter(width = 0.3, alpha = 0.2) +
stat_smooth(method = "lm", col = "red")
summary(lm_precip_humidity) # R^2 = 0.03742
lm_precip_dry <- lm(precip ~ dry_bulb_temp_f, data = train_data)
ggplot(lm_precip_dry, aes(x = dry_bulb_temp_f, y = precip)) +
geom_point(color = "grey30") +
geom_jitter(width = 0.3, alpha = 0.2) +
stat_smooth(method = "lm", col = "red")
summary(lm_precip_dry)
lm_precip_wind <- lm(precip ~ wind_speed, data = train_data)
ggplot(lm_precip_wind, aes(x = wind_speed, y = precip)) +
geom_point(color = "grey30") +
geom_jitter(width = 0.3, alpha = 0.2) +
stat_smooth(method = "lm", col = "red")
summary(lm_precip_wind)
lm_precip_pressure <- lm(precip ~ station_pressure, data = train_data)
ggplot(lm_precip_pressure, aes(x = station_pressure, y = precip)) +
geom_point(color = "grey30") +
geom_jitter(width = 0.3, alpha = 0.2) +
stat_smooth(method = "lm", col = "red")
summary(lm_precip_pressure) # R^2 = 0.01896
mlr_spec <- linear_reg() %>%
set_engine(engine = "lm") # Set the model type
train_fit_mlr <- mlr_spec %>%
fit(precip ~ relative_humidity + station_pressure, data = train_data) # Fit the model to a multiple linear regression model
train_results_mlr <- train_fit_mlr %>%
predict(new_data = train_data) %>%
mutate(truth = train_data$precip) # Pass the training data through the model to find performance metrics
rmse(train_results_mlr, truth = truth, estimate = .pred) # rmse = 0.04421933
rsq(train_results_mlr, truth = truth, estimate = .pred) # R^2 = 0.04616237 --> Percent variation that can be explained by the model.
poly_spec <- linear_reg() %>%
set_engine(engine ="lm")
train_fit_poly <- poly_spec %>%
fit(precip ~ poly(relative_humidity, 2, raw = TRUE), data = train_data) # Fit the model to a linear regression model with a quadratic term
train_results_poly <- train_fit_poly %>%
predict(new_data = train_data) %>%
mutate(truth = train_data$precip)
rmse(train_results_poly, truth = truth, estimate = .pred) # rmse = 0.043931
rsq(train_results_poly, truth = truth, estimate = .pred) # r^2 = 0.05856079
ggplot(train_data, aes(x = relative_humidity, y = precip)) + # Visualization of linear model with quadratic term
geom_point(color = "gray30") +
geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red")
set.seed(1234)
weather_recipe <- recipe(precip ~ ., data = train_data)
tune_spec <- linear_reg(penalty = tune(), mixture = 0) %>%  # A ridge regression model is tuned
set_engine("glmnet")
ridge_wf <- workflow() %>%
add_recipe(weather_recipe)
weather_cvfolds <- vfold_cv(train_data) # Cross validation is needed for the grid search below
lambda_grid <- grid_regular(levels = 50, penalty(range = c(-3,0.3)))# A grid search is used to tune the lambda hyperparameter
ridge_grid <- tune_grid(
ridge_wf %>%
add_model(tune_spec), resamples = weather_cvfolds, grid = lambda_grid)
show_best(ridge_grid, metric = "rmse") # A lambda of 0.0064 gives the lowest RMSE of 0.0404
show_best(ridge_grid, metric = "rsq") # A lambda of 0.0016 gives the highest R^2 of 0.0683
ridge_grid %>% # visualization of RMSE metric
collect_metrics() %>%
filter(.metric == "rmse") %>%
ggplot(aes(penalty, mean)) +
geom_line(size=1, color="red") +
scale_x_log10() +
ggtitle("Grid Search Results: RMSE")
ridge_grid %>% # visualization of R^2 metric
collect_metrics() %>%
filter(.metric == "rsq") %>%
ggplot(aes(penalty, mean)) +
geom_line(size=1, color="red") +
scale_x_log10() +
ggtitle("Grid Search Results: R-Squared")
mlr_spec <- linear_reg() %>%
set_engine(engine = "lm")
test_fit_mlr <- mlr_spec %>%
fit(precip ~ relative_humidity + station_pressure, data = test_data)
test_results_mlr <- test_fit_mlr %>%
predict(new_data = test_data) %>%
mutate(truth = test_data$precip) # Pass the testing data through the model to find performance metrics
rsq(test_results_mlr, truth = truth, estimate = .pred) # R^2 = 0.0676
poly_spec <- linear_reg() %>%
set_engine(engine ="lm")
test_fit_poly <- poly_spec %>%
fit(precip ~ poly(relative_humidity, 2, raw = TRUE), data = test_data)
test_results_poly <- test_fit_poly %>%
predict(new_data = test_data) %>%
mutate(truth = test_data$precip)
rsq(test_results_poly, truth = truth, estimate = .pred) # r^2 = 0.0894
ggplot(test_data, aes(x = relative_humidity, y = precip)) +
geom_point(color = "gray30") +
geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = "red")
set.seed(1234)
weather_recipe <- recipe(precip ~ ., data = test_data)
tune_spec <- linear_reg(penalty = tune(), mixture = 0) %>%  # A ridge regression model is tuned
set_engine("glmnet")
ridge_wf <- workflow() %>%
add_recipe(weather_recipe)
weather_cvfolds <- vfold_cv(test_data)
lambda_grid <- grid_regular(levels = 50, penalty(range = c(-3,0.3)))
ridge_grid <- tune_grid(
ridge_wf %>%
add_model(tune_spec), resamples = weather_cvfolds, grid = lambda_grid)
show_best(ridge_grid, metric = "rsq") # A lambda of 0.0010 gives the highest R^2 of 0.1374621
ridge_grid %>% # visualization of R^2 metric
collect_metrics() %>%
filter(.metric == "rsq") %>%
ggplot(aes(penalty, mean)) +
geom_line(size=1, color="red") +
scale_x_log10() +
ggtitle("Grid Search Results: R-Squared")
model_names <- c("MLR Model", "Quadratic Polynomial Model", "Regularized MLR Model")
train_rsq_error <- c(0.04616237, 0.05856079, 0.06829497)
test_rsq_error <- c(0.06760682, 0.0893642, 0.1374621)
comparison_df <- data.frame(model_names, train_rsq_error, test_rsq_error)
print(comparison_df)
best_performing_model_df <- comparison_df %>%
filter(test_rsq_error == max(test_rsq_error)) %>%
rename(best_performing_model = model_names)
print(best_performing_model_df)
knitr::opts_chunk$set(echo = TRUE)
install.packages("DBI", repos = "http://cran.us.r-project.org")
install.packages("tidyverse", repos = "http://cran.us.r-project.org")
install.packages("DBI", repos = "http://cran.us.r-project.org")
library(DBI)
install.packages("DBI", repos = "http://cran.us.r-project.org")
install.packages("DBI", repos = "http://cran.us.r-project.org")
install.packages("tidyverse", repos = "http://cran.us.r-project.org")
library(DBI)
library(tidyverse)
library(DBI)
library(odbc)
knitr::opts_chunk$set(echo = TRUE)
install.packages("DBI", repos = "http://cran.us.r-project.org")
install.packages("tidyverse", repos = "http://cran.us.r-project.org")
library(DBI)
install.packages("tidyverse", repos = "http://cran.us.r-project.org")
knitr::opts_chunk$set(echo = TRUE)
install.packages("DBI", repos = "http://cran.us.r-project.org")
install.packages("tidyverse", repos = "http://cran.us.r-project.org")
install.packages("DBI", repos = "http://cran.us.r-project.org")
install.packages("DBI", repos = "http://cran.us.r-project.org")
knitr::opts_chunk$set(echo = TRUE)
library(DBI)
library(tidyverse)
con <- dbConnect(odbc::odbc(), "SQL Server")
setwd("C:/Users/gyrus/OneDrive/Documents/GitHub/Professional Resume")
